{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster analysis of SDMoA paintings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from itertools import cycle #for plotting clusters\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from sklearn.cluster import AffinityPropagation, KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn.manifold import TSNE \n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matrix of average emotion scores for each painting as a pandas df\n",
    "aveEmotionsMATLAB = pd.read_csv(\"aveEmotion.csv\");\n",
    "#aveEmotionsMATLAB.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all rating data\n",
    "ratingData = np.empty((109, 10, 21))\n",
    "\n",
    "for i in range(1,22):\n",
    "    ratingData[:,:,i-1] = pd.read_excel(\"ratingData-sorted.xlsx\", sheet_name=i, usecols=range(3,13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check to make sure the order of paintings is the same for all subjects\n",
    "for i in range(0,21):\n",
    "    print((ratingData[:,0,i] == ratingData[:,0,0]).all())\n",
    "#ratingData[:,0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An exploration in normalization..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histograms of scores for each emotion for sub01 (pre-normalizing)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=3, sharey = True, sharex = True, figsize=(12,10))\n",
    "\n",
    "#plt.setp(axes, xticks=[1,2,3,4,5,6,7]) \n",
    "emotionList=[\"Moved\",\"Fascin\",\"Funny\",\"Surprised\",\"Indiff\",\"Calm\",\"Unset\",\"Personal\",\"Curious\"]\n",
    "fig.suptitle(\"Num Ratings per Emotion: Sub01\", size=16)\n",
    "\n",
    "dim=331\n",
    "for i in range(1,10):\n",
    "    plt.subplot(dim+(i-1), \\\n",
    "                      xlabel=\"Score\", ylabel=\"Num Times Used\",\\\n",
    "                      xticks=np.arange(1,8,1)\n",
    "                     )\n",
    "    plt.hist(ratingData[:,i,0], range=[1, 8], bins=7, align='left')\n",
    "    plt.title(emotionList[i-1])\n",
    "                  \n",
    "plt.tight_layout(pad=3.0)\n",
    "fig.subplots_adjust(top=0.88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram of average Moved score for sub02\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=3, sharey = True, sharex = True, figsize=(12,10))\n",
    "\n",
    "emotionList=[\"Moved\",\"Fascin\",\"Funny\",\"Surprised\",\"Indiff\",\"Calm\",\"Unset\",\"Personal\",\"Curious\"]\n",
    "fig.suptitle(\"Num Ratings per Emotion: Sub02\", size=16)\n",
    "\n",
    "dim=331\n",
    "for i in range(1,10):\n",
    "    plt.subplot(dim+(i-1), \\\n",
    "                      xlabel=\"Score\", ylabel=\"Num Times Used\",\\\n",
    "                      xticks=np.arange(1,8,1)\n",
    "                     )\n",
    "    plt.hist(ratingData[:,i,1], range=[1, 8], bins=7, align='left')\n",
    "    plt.title(emotionList[i-1])\n",
    "                  \n",
    "plt.tight_layout(pad=3.0)\n",
    "fig.subplots_adjust(top=0.88)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different emotions have really different distributions, even within a subject, so I definitely agree that we should standardize per subject & emotion rather than just subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize data per person per emotion (find mean, find sd, substract mean and divide by sd)\n",
    "standardRating = np.copy(ratingData)\n",
    "\n",
    "for i in range(0,20): #per subject\n",
    "    for j in range(1,10): #per emotion\n",
    "        # standardize across all paintings for this subject/emotion\n",
    "        standardRating[:,j,i] = preprocessing.scale(ratingData[:,j,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just making sure this^ did something\n",
    "print(ratingData[0,:,0])\n",
    "print(standardRating[0,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also tried computing this without using the preprocessing module, just to double check it was doing the same thing and indeed it was! But there was an error: RuntimeWarning: invalid value encountered in double_scalars so I'm using the preprocessing. This was the other version:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardRatingByHand = np.copy(ratingData)\n",
    "\n",
    "#for i in range(0,20):\n",
    "    #for j in range(0,9):\n",
    "        #mean = np.nanmean(standardRatingByHand[:,j,i])\n",
    "        #sd = np.nanstd(standardRatingByHand[:,j,i])\n",
    "        #for k in range(0,109):\n",
    "            #standardRatingByHand[k,j,i] = (standardRatingByHand[k,j,i]-mean)/sd\n",
    "\n",
    "# np.allclose(standardRating,standardRatingByHand, equal_nan=True) --> this outputs True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram of average scores for each emotin for sub01 - post-standarizing\n",
    "fig, axes = plt.subplots(nrows=3, ncols=3, sharey = True, sharex = True, figsize=(12,10))\n",
    "\n",
    "emotionList=[\"Moved\",\"Fascin\",\"Funny\",\"Surprised\",\"Indiff\",\"Calm\",\"Unset\",\"Personal\",\"Curious\"]\n",
    "fig.suptitle(\"Num Ratings per Emotion Standardized: Sub01\", size=16)\n",
    "\n",
    "dim=331\n",
    "for i in range(1,10):\n",
    "    #xmin, xmax = min(standardRating[:,i,0]), max(standardRating[:,i,0])\n",
    "    plt.subplot(dim+(i-1), \\\n",
    "                      xlabel=\"Score\", ylabel=\"Num Times Used\",\\\n",
    "                    xticks=np.arange(-3, 4, 1)\n",
    "                     )\n",
    "    plt.hist(standardRating[:,i,0], bins=7, range=[-3.0, 4.0], align='left')\n",
    "    plt.title(emotionList[i-1])\n",
    "                  \n",
    "plt.tight_layout(pad=3.0)\n",
    "fig.subplots_adjust(top=0.88)\n",
    "\n",
    "# for i in range(0,9):\n",
    "#     plt.subplot(dim+i)\n",
    "#     plt.hist(standardRating[:,i+1,0], bins=7)\n",
    "#     plt.title(emotionList[i])\n",
    "    \n",
    "# plt.tight_layout()\n",
    "# fig.subplots_adjust(top=0.88)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looks like this didn't change the distribution at all? Might be a visualization issue on my end though. I was having trouble with this graphs >:(\n",
    "\n",
    "Robert: I don't think we would expect this to change the distribution, if we are still using the same number of bins (7) with equal spacing. The scores have changed though, are now seen in standard units. (0 is mean, +/- vals are multiples of std. dev.)\n",
    "\n",
    "### : )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is what I did before - can ignore\n",
    "#standardRating = ratingData\n",
    "\n",
    "#for i in range(0,20):\n",
    "    #standardRating[:,:,i] = preprocessing.scale(ratingData[:,:,i], axis=1)\n",
    "    \n",
    "#print(standardRating[:,:,20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recreating the matrix of averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# means of each painting's emotion\n",
    "aveEmotionsCopy = standardRating.copy()\n",
    "aveEmotions = aveEmotionsCopy[:,:,1]\n",
    "\n",
    "for i in range(0,109):\n",
    "    for j in range(1,10):\n",
    "        aveEmotions[i,j] = np.nanmean(aveEmotionsCopy[i,j,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turing aveEmotions into a df\n",
    "aECols = ['ID','Moved','Fascinated','Funny','Surprised','Indifferent','Calm','Unsettling','Personal','Curious']\n",
    "aveEmotions = pd.DataFrame(data=aveEmotions, columns=aECols)\n",
    "aveEmotions.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create matrix of variance scores for each painting\n",
    "# not using this for anything - just wanted to see what it looked like. Overall, pretty uniform, with a few exceptions.\n",
    "varsPerPainting = np.zeros(109)\n",
    "\n",
    "for i in range(0,109):\n",
    "    varsPerPainting[i] = np.nanvar(standardRating[i,1:10,:])\n",
    "    \n",
    "varsPerPainting = pd.DataFrame(data=varsPerPainting, columns=['Universal Var'])\n",
    "varsPerPainting.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create matrix of variance scores for each emotional dimension per painting\n",
    "varsPerEmotionCopy = standardRating.copy()\n",
    "varsPerEmotion = varsPerEmotionCopy[:,:,1]\n",
    "\n",
    "for i in range(0,109):\n",
    "    for j in range(1,10):\n",
    "        varsPerEmotion[i,j] = np.nanvar(varsPerEmotionCopy[i,j,:])\n",
    "        \n",
    "varCols = ['ID','Moved Var','Fascin Var','Funny Var','Surp Var','Indiff Var','Unset Var','Calm Var','Personal Var','Curious Var']\n",
    "varsPerEmotion = pd.DataFrame(data=varsPerEmotion, columns=varCols)\n",
    "#adding the total variance because I can\n",
    "varsPerEmotion = varsPerEmotion.join(varsPerPainting)\n",
    "varsPerEmotion.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create aveEmotions copy without ID column to be used for clustering\n",
    "\n",
    "X = aveEmotions.drop(['ID'],axis=1)\n",
    "X = X.to_numpy()\n",
    "\n",
    "#X = np.delete(aveEmotions, 0, axis=1) # <-- can't remember what this does but it was there last time so.....\n",
    "#print(X[:10]) # first ten rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensional Reduction (t-SNE)\n",
    "\n",
    "So we can plot our 9-dim data in 2-d.\n",
    "\n",
    "Sydney: I set perplexity to 20, which is kind of an arbitrary number, since I think that's around the average number of paintings in each gallery....\n",
    "\n",
    "Robert: I played around and settled on 30. but you're right the choice is arbitrary.\n",
    "\n",
    "See Notes on t-SNE: [https://distill.pub/2016/misread-tsne/](https://distill.pub/2016/misread-tsne/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choice of perplexity is subjective, until you see a good layout/separation\n",
    "# tsne = TSNE(n_components=2, perplexity = 20, random_state = 0) \n",
    "\n",
    "tsne = TSNE(n_components=2, perplexity = 30, random_state = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tSNE performed on aveEmotions data\n",
    "\n",
    "X_tsned = tsne.fit_transform(X)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "tsned = plt.scatter(X_tsned[:,0],X_tsned[:,1],c='r')\n",
    "plt.title('t-SNEd dimensional reduction of painting scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__NOTE__: UMAP is another dimensional reduction technique we could explore. \n",
    "\n",
    "- https://umap-learn.readthedocs.io/en/latest/\n",
    "- https://arxiv.org/abs/1802.03426\n",
    "\n",
    "Would have to look into whether it is appropriate for our use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering time!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shared clustering code and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "af = AffinityPropagation()\n",
    "\n",
    "ratings = np.array([1,2,3,4,5,6,7,8,9])\n",
    "\n",
    "# function to get a table of the amount of paintings in each cluster\n",
    "#whichCluster is a string\n",
    "def amountInCluster(whichCluster,numClusters):\n",
    "    clusterList = list(range(0,numClusters,1))\n",
    "    clusterAmount = list(range(0,numClusters,1))\n",
    "\n",
    "    for i in range(0,numClusters):\n",
    "        clusterAmount[i] = aveEmotions[whichCluster][(aveEmotions[whichCluster] == i)].count()\n",
    "    \n",
    "    clusterDict = {'Cluster': clusterList, 'numItems': clusterAmount}\n",
    "    clusterAmounts = pd.DataFrame.from_dict(clusterDict)\n",
    "    \n",
    "    return clusterAmounts\n",
    "\n",
    "# function to get col means for each cluster\n",
    "\n",
    "#whichCluster is a str\n",
    "def addColAverage(whichCluster,clusterNum):  \n",
    "    cluster = aveEmotions[(aveEmotions[whichCluster] == clusterNum)] #grabs paintings in a cluster\n",
    "    means = cluster.mean() #col means\n",
    "#     means = means.drop(labels = [\"ID\",\"ClusterAfter\",\"ClusterBefore\",\"ClusterKMeans\"]) #drop Cluster labels\n",
    "    means = means.drop(labels = [\"ID\",\"ClusterBefore\"]) #drop Cluster labels\n",
    "    means = means.to_numpy() #converts series to numpy array\n",
    "    \n",
    "    return means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering After t-SNE (this is what I originally had, and where the graphs I sent came from)\n",
    "\n",
    "Robert: I'm going to comment this out, because we shouldn't use it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Cluster! That! Data!\n",
    "# clustering = af.fit(X_tsned) \n",
    "\n",
    "# cluster_centers_indices = af.cluster_centers_indices_\n",
    "# labels = af.labels_\n",
    "\n",
    "# n_clusters_ = len(cluster_centers_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 8 clusters this time!\n",
    "\n",
    "# print(cluster_centers_indices)\n",
    "# print(labels)\n",
    "# print(n_clusters_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #adding labels to a new aveEmotions df\n",
    "# aveEmotions['ClusterAfter'] = list(labels)\n",
    "# aveEmotions['ClusterBefore'] = np.nan \n",
    "# aveEmotions['ClusterKMeans'] = np.nan #this is empty for now so certain functions Work\n",
    "# aveEmotions.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from sklearn's demo of affinity propogation\n",
    "\n",
    "# plt.close('all')\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.clf()\n",
    "\n",
    "# colors = cycle('bgrcmykbgrcmykbgrcmykbgrcmyk')\n",
    "# for k, col in zip(range(n_clusters_), colors):\n",
    "#     class_members = labels == k\n",
    "#     cluster_center = X_tsned[cluster_centers_indices[k]]\n",
    "#     plt.plot(X_tsned[class_members, 0], X_tsned[class_members, 1], col + '.')\n",
    "#     plt.plot(cluster_center[0], cluster_center[1], 'o', markerfacecolor=col, \n",
    "#              markeredgecolor='k', markersize=14)\n",
    "#     for x in X_tsned[class_members]:\n",
    "#         plt.plot([cluster_center[0], x[0]], [cluster_center[1], x[1]], col)\n",
    "\n",
    "# plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # function to get a table of the amount of paintings in each cluster\n",
    "\n",
    "# #whichCluster is a string\n",
    "# def amountInCluster(whichCluster,numClusters):\n",
    "#     clusterList = list(range(0,numClusters,1))\n",
    "#     clusterAmount = list(range(0,numClusters,1))\n",
    "\n",
    "#     for i in range(0,numClusters):\n",
    "#         clusterAmount[i] = aveEmotions[whichCluster][(aveEmotions[whichCluster] == i)].count()\n",
    "    \n",
    "#     clusterDict = {'Cluster': clusterList, 'numItems': clusterAmount}\n",
    "#     clusterAmounts = pd.DataFrame.from_dict(clusterDict)\n",
    "    \n",
    "#     return clusterAmounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clusterCountAfter = amountInCluster('ClusterAfter',n_clusters_)\n",
    "# clusterCountAfter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # function to get col means for each cluster\n",
    "\n",
    "# #whichCluster is a str\n",
    "# def addColAverage(whichCluster,clusterNum):  \n",
    "#     cluster = aveEmotions[(aveEmotions[whichCluster] == clusterNum)] #grabs paintings in a cluster\n",
    "#     means = cluster.mean() #col means\n",
    "#     means = means.drop(labels = [\"ID\",\"ClusterAfter\",\"ClusterBefore\",\"ClusterKMeans\"]) #drop Cluster labels\n",
    "#     means = means.to_numpy() #converts series to numpy array\n",
    "    \n",
    "#     return means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #this will be the x vals for plotting\n",
    "# ratings = np.array([1,2,3,4,5,6,7,8,9])\n",
    "\n",
    "# #this checks to make sure addColAverage works\n",
    "# #print(type(addColAverage(\"ClusterAfter\",0)))\n",
    "# print(addColAverage(\"ClusterAfter\",0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot the emotion averages of each cluster\n",
    "\n",
    "# fig, axes= plt.subplots(nrows=2, ncols=4, sharey = True, figsize=(16,6))\n",
    "\n",
    "# plt.setp(axes, xticks=[1,2,3,4,5,6,7,8,9]) #, xticklabels=[\"Moved\",\"Fascin\",\"Funny\",\"Surprised\",\n",
    "#                                                         #\"Indiff\",\"Calm\",\"Unset\",\"Personal\",\"Curious\"]) #adds tick marks for each emotion category\n",
    "# k = 0\n",
    "# for i in range(0,2):\n",
    "#     for j in range(0,4):\n",
    "#         axes[i,j].plot(ratings, addColAverage(\"ClusterAfter\",k))\n",
    "#         axes[i,j].set_title('Cluster {number}'.format(number = k))\n",
    "#         k = k+1\n",
    "\n",
    "# plt.tight_layout()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Before t-SNE\n",
    "\n",
    "Robert: This is what we want!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting X (9-dim) instead of transformed X_tsned\n",
    "clustering2 = af.fit(X) \n",
    "                             \n",
    "cluster_centers_indices2 = af.cluster_centers_indices_\n",
    "labels2 = af.labels_\n",
    "n_clusters_2 = len(cluster_centers_indices2)\n",
    "\n",
    "aveEmotions['ClusterBefore'] = labels2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aveEmotions.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#11 clusters now\n",
    "\n",
    "print(cluster_centers_indices2)\n",
    "print(labels2)\n",
    "print(n_clusters_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm not sure I'm doing what you want me to do here...I'm trying to use the transformed data (which should be the same as it was above) to plot the clusters you get when considering all 9 dimensions. The cluster look a little weird, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using X_tsned (transformed data) instead of X\n",
    "\n",
    "plt.close('all')\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.clf()\n",
    "\n",
    "colors = cycle('bgrcmykbgrcmykbgrcmykbgrcmyk')\n",
    "for k, col in zip(range(n_clusters_2), colors):\n",
    "    class_members = labels2 == k\n",
    "    cluster_center = X_tsned[cluster_centers_indices2[k]]\n",
    "    plt.plot(X_tsned[class_members, 0], X_tsned[class_members, 1], col + '.')\n",
    "    plt.plot(cluster_center[0], cluster_center[1], 'o', markerfacecolor=col,\n",
    "             markeredgecolor='k', markersize=14)\n",
    "    for x in X_tsned[class_members]:\n",
    "        plt.plot([cluster_center[0], x[0]], [cluster_center[1], x[1]], col )\n",
    "\n",
    "plt.title('Estimated number of clusters: %d' % n_clusters_2)\n",
    "plt.show()\n",
    "\n",
    "#fig.savefig('cluster-graph.png') <--this......does not work :( i can't figure out where to place \"fig\" w/o ruining the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterCountBefore = amountInCluster('ClusterBefore',n_clusters_2)\n",
    "clusterCountBefore.numItems[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ratings, np.array(addColAverage(\"ClusterBefore\",0)))\n",
    "# print(type(addColAverage(\"ClusterBefore\",0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the emotion averages of each cluster\n",
    "\n",
    "fig, axes= plt.subplots(nrows=6, ncols=2, sharey = True, figsize=(12,18))\n",
    "\n",
    "plt.setp(axes, xticks=[1,2,3,4,5,6,7,8,9], \\\n",
    "         xticklabels=[\"Moved\",\"Fascin\",\"Funny\",\"Surprised\", \"Indiff\",\"Calm\",\"Unset\",\"Personal\",\"Curious\"], \\\n",
    "#         rotation=45\n",
    "        ) #adds tick marks for each emotion category\n",
    "fig.suptitle(\"Average Emotion Rating per Cluster (Std Units)\", size=16)\n",
    "\n",
    "k = 0\n",
    "for i in range(0,6):\n",
    "    for j in range(0,2):\n",
    "        if k<n_clusters_2:\n",
    "            axes[i,j].plot(ratings, addColAverage(\"ClusterBefore\",k))\n",
    "            axes[i,j].set_title('Cluster {number} (n={amount})'.format(number = k, amount=clusterCountBefore.numItems[k]))\n",
    "            k = k+1\n",
    "\n",
    "plt.tight_layout(pad=3.0)\n",
    "fig.subplots_adjust(top=0.95)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('cluster-averages-linegraph.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm putting all the stuff I had here about combining clusters in another document - I don't think we'll need it anymore haha."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Before t-SNE (KMeans)\n",
    "\n",
    "Robert: not used here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #fitting X (9-dim) instead of transformed X_tsned\n",
    "# n_clusters_km = 13\n",
    "# km = KMeans(n_clusters=n_clusters_km)\n",
    "\n",
    "# clusteringkm = km.fit(X) \n",
    "                             \n",
    "# labelskm = km.labels_\n",
    "\n",
    "# aveEmotions['ClusterKMeans'] = labelskm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # using X_tsned (transformed data) instead of X\n",
    "\n",
    "# plt.close('all')\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# plt.clf()\n",
    "\n",
    "# colors = cycle('bgrcmykbgrcmykbgrcmykbgrcmyk')\n",
    "# for k, col in zip(range(n_clusters_km), colors):\n",
    "#     class_members = labelskm == k\n",
    "#     plt.plot(X_tsned[class_members, 0], X_tsned[class_members, 1], col + '.')\n",
    "\n",
    "# plt.title('Estimated number of clusters: %d' % n_clusters_km)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining everything together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing all rating data to recover painting names/galleries\n",
    "\n",
    "names = pd.read_excel(\"ratingData-sorted.xlsx\", sheet_name=1, usecols=range(0,4))\n",
    "names.rename(columns = {\"Unique ID\":\"ID\"}, inplace = True)\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#everything at once\n",
    "labeledRatings = names.merge(aveEmotions, on=['ID'])\n",
    "# labeledRatings = labeledRatings.drop(['ClusterAfter', 'ClusterKMeans'], axis=1)\n",
    "labeledRatings = labeledRatings.merge(varsPerEmotion, on=['ID'])\n",
    "labeledRatings.head()\n",
    "\n",
    "\n",
    "labeledRatings.to_excel('labeledRatings.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeledRatings[(labeledRatings['ClusterBefore'] == 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a cluster, creates a list of the number of paintings in each gallery\n",
    "galleryList = list([\"1\",\"2\",\"3\",\"100\",\"16\",\"19\",\"200\"])\n",
    "galleries = [1,2,3,100,16,19,200]\n",
    "\n",
    "def numInGallery(clusterNum):\n",
    "\n",
    "    numIn = np.zeros(7)\n",
    "    \n",
    "    sampleCluster = labeledRatings.ClusterBefore == clusterNum\n",
    "    \n",
    "    for i in range(0,7):\n",
    "        sampleGal = labeledRatings.Gallery==galleries[i]\n",
    "        numIn[i]= len(labeledRatings[sampleCluster & sampleGal])\n",
    "    \n",
    "    numIn = list(numIn)\n",
    "    \n",
    "    return numIn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each cluster, plot num paintings in each gallery \n",
    "\n",
    "fig, axes= plt.subplots(nrows=3, ncols=4, sharey = True, figsize=(16,12))  #[1,2,3,100,16,19,200]\n",
    "\n",
    "#plt.setp(axes, xticks=[1,2,3,3,4,5,6,7]) #, yticks=[1,2,3,4,5,6,7,8]) #, xticklabels=[\"Moved\",\"Fascin\",\"Funny\",\"Surprised\",\n",
    "                                                        #\"Indiff\",\"Calm\",\"Unset\",\"Personal\",\"Curious\"]) #adds tick marks for each emotion category\n",
    "fig.suptitle(\"Num of Paintings in each Gal Per Cluster\", size=16)\n",
    "numGals = [1,2,3,4,5,6,7]\n",
    "\n",
    "k = 0\n",
    "for i in range(0,3):\n",
    "    for j in range(0,4):\n",
    "        if k<n_clusters_2:\n",
    "            axes[i,j].bar(numGals, numInGallery(k))\n",
    "            axes[i,j].set_title('Cluster {number}'.format(number = k))\n",
    "            axes[i,j].set_xticks([1,2,3,4,5,6,7])\n",
    "            axes[i,j].set_xticklabels(galleryList)\n",
    "            if j==0:\n",
    "                axes[i,j].set_ylabel(\"Num of Paintings in Gallery\")\n",
    "                if i==2:\n",
    "                    axes[i,j].set_xlabel(\"Gallery Number\")\n",
    "            k = k+1\n",
    "\n",
    "plt.tight_layout(pad=3.0)\n",
    "fig.subplots_adjust(top=0.88)\n",
    "fig.savefig('num-paintings-in-gal.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Highest Scores\n",
    "\n",
    "#most moving\n",
    "#print(labeledRatings.iloc[(labeledRatings['Moved'].idxmax())])\n",
    "\n",
    "#most fascinating\n",
    "#print(labeledRatings.iloc[(labeledRatings['Fascinated'].idxmax())])\n",
    "\n",
    "#most funny\n",
    "#print(labeledRatings.iloc[(labeledRatings['Funny'].idxmax())])\n",
    "\n",
    "#most surprised\n",
    "#print(labeledRatings.iloc[(labeledRatings['Surprised'].idxmax())])\n",
    "\n",
    "#most indifferent\n",
    "#print(labeledRatings.iloc[(labeledRatings['Indifferent'].idxmax())])\n",
    "\n",
    "#most calm\n",
    "#print(labeledRatings.iloc[(labeledRatings['Calm'].idxmax())])\n",
    "\n",
    "#most unsettling\n",
    "#print(labeledRatings.iloc[(labeledRatings['Unsettling'].idxmax())])\n",
    "\n",
    "#most personal\n",
    "#print(labeledRatings.iloc[(labeledRatings['Personal'].idxmax())])\n",
    "\n",
    "#most curious\n",
    "#print(labeledRatings.iloc[(labeledRatings['Curious'].idxmax())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create 2 dfs: variability, ave score, and diff. sort on diff\n",
    "\n",
    "#Fascination\n",
    "fascination = labeledRatings.loc[:,['Title','Artist','Gallery','ID','Fascinated', 'Fascin Var']]\n",
    "fascination['Diff'] = fascination['Fascinated'] - fascination['Fascin Var']\n",
    "fascination = fascination.sort_values(by=['Diff'], ascending=False)\n",
    "\n",
    "#Indifference\n",
    "indiff = labeledRatings.loc[:,['Title','Artist','Gallery','ID','Indifferent', 'Indiff Var']]\n",
    "indiff['Diff'] = indiff['Indifferent'] - indiff['Indiff Var']\n",
    "indiff = indiff.sort_values(by=['Indifferent'], ascending=False) ##sorting by rating\n",
    "\n",
    "#Unsettling\n",
    "unsettled = labeledRatings.loc[:,['Title','Artist','Gallery','ID','Unsettling', 'Unset Var']]\n",
    "unsettled['Diff'] = unsettled['Unsettling'] - unsettled['Unset Var']\n",
    "unsettled = unsettled.sort_values(by=['Unsettling'], ascending=False) ##sorting by rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unsettled & Indifferent --> top 20 that have variance less than 2\n",
    "\n",
    "#labeledRatings[(labeledRatings['ClusterBefore'] == 4)]\n",
    "unsettledSmall = unsettled[(unsettled['Unset Var']<2)]\n",
    "unsettledSmall = unsettledSmall.head(n=20)\n",
    "\n",
    "indiffSmall = indiff[(indiff['Indiff Var']<2)]\n",
    "indiffSmall = indiffSmall.head(n=20)\n",
    "\n",
    "fascinationSmall = fascination.head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsettledSmall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#['Title','Artist','Gallery','ID']\n",
    "paintingList = pd.concat([fascinationSmall, unsettledSmall, indiffSmall], sort=False)\n",
    "paintingList.to_excel('paintingList.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
